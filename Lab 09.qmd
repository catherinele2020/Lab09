---
title: "Lab 09"
author: Catherine Le
format: html
editor: visual
---

## Preliminary

```{r}
library(microbenchmark)
library(parallel)
```

## **Problem 1: Vectorization**

1.  This function generates an `n x k` dataset with all its entries drawn from a Poission distribution with mean `lambda`.

```{r}
# the function from the lab
fun1 <- function(n = 100, k = 4, lambda = 4) {
  x <- NULL
  
  for (i in 1:n){
    x <- rbind(x, rpois(k, lambda))    
  }
  
  return(x)
}

```

```{r}
# my code
# eliminates the need for a loop and an rbind
fun1alt <- function(n = 100, k = 4, lambda = 4) {
  x <- matrix(rpois(n * k, lambda), nrow = n, ncol = k)
  return(x)
}
```

```{r}
# checking the dimensions of the matrices
# set seed for reproducibility
set.seed(42)
n <- 100
k <- 4
lambda <- 4

matrix1 <- fun1(n, k, lambda)
matrix2 <- fun1alt(n, k, lambda)

# check dimensions
cat("Dimensions of matrix1:", dim(matrix1), "\n")
cat("Dimensions of matrix2:", dim(matrix2), "\n")
```

```{r}
# seeing if the distributions are similar
ks_test_result <- ks.test(matrix1, matrix2)
print(ks_test_result)
```

The p-value is 1 which indicates that there is no evidence that suggests that the two matrices have significantly different distributions.

```{r}
# Benchmarking
microbenchmark::microbenchmark(
  fun1(),
  fun1alt()
)
```

The fun1alt() function has a lower mean execution time than the fun1() function. This suggests that fun1alt() is more efficient in terms of execution time.

2.  This function finds the maximum value of each column of a matrix (hint: check out the `max.col()` function).

```{r}
# the function in the lab

# Find each column's max value
fun2 <- function(x) {
  result <- apply(x, 2, max)
  return(result)
}

```

```{r}
# my function
fun2alt <- function(x) {
  max_values <- matrixStats::colMaxs(x)
  return(max_values)
}
```

```{r}
set.seed(1234)
x <- matrix(rnorm(1e4), nrow = 10)

result1 <- fun2(x)
result2 <- fun2alt(x)

# Find the indices where the results differ
differences <- which(result1 != result2)

if (length(differences) == 0) {
  cat("Results are the same.\n")
} else {
  cat("Results are not the same. Differences found at indices:", differences, "\n")
}
```

```{r}
set.seed(1234)
x <- matrix(rnorm(1e4), nrow = 10)

result_fun2 <- fun2(x)
result_fun2alt <- fun2alt(x)

# benchmarking
mb <- microbenchmark(
  fun2(x),
  fun2alt(x)
)

print(mb)
```

The fun2alt() function has a lower mean execution time than the fun2() function. This suggests that fun2alt() is more efficient in terms of execution time.

## **Problem 3: Parallelization**

```{r}
my_boot <- function(dat, stat, R, ncpus = 1L) {
  
  # Getting the random indices
  n <- nrow(dat)
  idx <- matrix(sample.int(n, n * R, TRUE), nrow = n, ncol = R)
  
  # PARALLELIZE THIS PART
  ans <- mclapply(seq_len(R), function(i) {
    result <- stat(dat[idx[, i], , drop = FALSE])
    return(result)
  }, mc.cores = ncpus)
  
  # Converting the list into a matrix
  ans <- do.call(rbind, ans)

  return(ans)
}
```

```{r}
# comparing it to a parametric model
# Bootstrap of an OLS
my_stat <- function(d) coef(lm(y ~ x, data=d))

# DATA SIM
set.seed(1)
n <- 500; R <- 1e4

x <- cbind(rnorm(n)); y <- x*5 + rnorm(n)

# Checking if we get something similar as lm
ans0 <- confint(lm(y~x))
ans1 <- my_boot(dat = data.frame(x, y), my_stat, R = R, ncpus = 2L)

# You should get something like this
t(apply(ans1, 2, quantile, c(.025,.975)))
##                   2.5%      97.5%
## (Intercept) -0.1372435 0.05074397
## x            4.8680977 5.04539763
ans0
##                  2.5 %     97.5 %
## (Intercept) -0.1379033 0.04797344
## x            4.8650100 5.04883353
```

```{r}
# time test
system.time(my_boot(dat = data.frame(x, y), my_stat, R = 4000, ncpus = 1L))
system.time(my_boot(dat = data.frame(x, y), my_stat, R = 4000, ncpus = 2L))
```

The user CPU time---the actual time spent on computations---is lower for the second call (2 CPU cores) than for the first call (1 CPU core). This shows that the second call appears to be more efficient in terms of user CPU time.
